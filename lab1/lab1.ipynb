{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print('-------------------')\n",
    "print('|     lab1         |')\n",
    "print('-------------------')\n",
    "\n",
    "# 데이터 다운로드 및 추출\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz\"\n",
    "urllib.request.urlretrieve(url, \"housing.tgz\")\n",
    "\n",
    "tar = tarfile.open(\"housing.tgz\")\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# 데이터 로드\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "print(housing.describe())\n",
    "print(housing.info())\n",
    "\n",
    "\n",
    "class CombinedAttributesAdder():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.sk = StandardScaler()\n",
    "\n",
    "    def fit_and_transform(self, train_df, test_df):\n",
    "        train_df, test_df = self._DataHandler(train_df, test_df)\n",
    "        return train_df, test_df\n",
    "\n",
    "    def _Encoder(self, train_df, test_df):\n",
    "        feature = 'ocean_proximity'\n",
    "        train_df[feature] = self.le.fit_transform(train_df[feature])\n",
    "        test_df[feature] = self.le.transform(test_df[feature])\n",
    "        return train_df, test_df\n",
    "\n",
    "    def _Norm(self, train_df, test_df):\n",
    "        numeric_features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "                            'total_bedrooms', 'population', 'households']\n",
    "        for feature in numeric_features:\n",
    "            train_df[feature] = self.sk.fit_transform(train_df[[feature]])\n",
    "            test_df[feature] = self.sk.transform(test_df[[feature]])\n",
    "        return train_df, test_df\n",
    "\n",
    "    def _DataHandler(self, train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "        train_df, test_df = self._Encoder(train_df, test_df)\n",
    "        train_df, test_df = self._Norm(train_df, test_df)\n",
    "        return train_df, test_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T05:16:04.576529Z",
     "start_time": "2024-09-13T05:16:04.372912Z"
    }
   },
   "id": "78a5226fa6707ab3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "|     lab1         |\n",
      "-------------------\n",
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0  -0.338843  0.688257           -0.683696    -0.260974       -0.167124   \n",
      "1   0.825017 -0.737132            0.426250     0.085779        0.171276   \n",
      "2   0.849992 -0.811906           -0.604414     0.251598       -0.212086   \n",
      "3   0.680159 -0.732458            1.456914    -0.588947       -0.363538   \n",
      "4   1.119728 -1.218493            0.188405    -0.669108       -0.510257   \n",
      "\n",
      "   population  households  median_income  median_house_value  ocean_proximity  \n",
      "0   -0.122422   -0.111131         1.5319             50500.0                1  \n",
      "1    0.258365    0.154393         3.5547            197600.0                0  \n",
      "2   -0.007218   -0.077290         6.8268            280300.0                0  \n",
      "3    0.024441   -0.332401         1.7292            191700.0                0  \n",
      "4   -0.722184   -0.603132         2.8611            314300.0                4  \n",
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "18000   1.254596 -1.368042           -0.287287     0.022566        0.140512   \n",
      "18001  -1.427777  0.973335            1.615478     0.364281        0.377155   \n",
      "18002   1.229620 -1.354022           -0.287287     0.098147        0.254101   \n",
      "18003  -1.088110  0.800419           -0.842260    -0.313652       -0.678273   \n",
      "18004  -0.458726  0.772379           -0.921541    -0.099736        0.135779   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "18000    0.459752    0.141377         2.8964            104300.0   \n",
      "18001    0.825589    0.422521         3.6885            254000.0   \n",
      "18002    0.745562    0.347028         2.2000             98700.0   \n",
      "18003   -0.720425   -0.819196         8.1871            500001.0   \n",
      "18004    0.934636    0.216869         1.0955             62700.0   \n",
      "\n",
      "       ocean_proximity  \n",
      "18000                4  \n",
      "18001                3  \n",
      "18002                4  \n",
      "18003                0  \n",
      "18004                1  \n"
     ]
    }
   ],
   "execution_count": 6,
   "source": [
    "housing = housing.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_df = housing.iloc[:18000].copy()\n",
    "test_df = housing.iloc[18000:].copy()\n",
    "\n",
    "handler = CombinedAttributesAdder()\n",
    "train_df, test_df = handler.fit_and_transform(train_df=train_df, test_df=test_df)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ],
   "id": "3b7d47d490b350c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T05:22:14.713572Z",
     "start_time": "2024-09-13T05:21:37.761467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_x = train_df.drop(['median_house_value'], axis=1)\n",
    "test_x = test_df.drop(['median_house_value'], axis=1)\n",
    "\n",
    "train_y = train_df['median_house_value']\n",
    "test_y = test_df['median_house_value']\n",
    "\n",
    "train_x[\"income_cat\"] = pd.cut(train_df[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "test_x[\"income_cat\"] = pd.cut(test_df[\"median_income\"],\n",
    "                              bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                              labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "train_x = pd.get_dummies(train_x, columns=['income_cat'])\n",
    "test_x = pd.get_dummies(test_x, columns=['income_cat'])"
   ],
   "id": "cc787c307566a939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "테스트 세트 성능:\n",
      "RMSE: 47146.123444419885\n",
      "R2: 0.8384978723054587\n"
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "xgb_reg = xgb.XGBRegressor(random_state=123)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'learning_rate': [0.01, 0.1, 0.3], \n",
    "    'max_depth': [5, 7, 10], \n",
    "}\n",
    "grid_search = GridSearchCV(xgb_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(train_x, train_y)\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "test_predictions = best_model.predict(test_x)\n",
    "test_mse = mean_squared_error(test_y, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(test_y, test_predictions)\n",
    "\n",
    "print(\"테스트 세트 성능:\")\n",
    "print(\"RMSE:\", test_rmse)\n",
    "print(\"R2:\", test_r2)"
   ],
   "id": "83343e47adfed5b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 베이지안 최적화로 object function optimize",
   "id": "db3559f8f510ba22"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-13T05:40:28.042855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from hyperopt import hp\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import STATUS_OK, fmin, tpe, Trials\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_search_space = {\n",
    "    'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "}"
   ],
   "id": "744a97c720de173",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [14:20<00:00,  1.72s/trial, best loss: 2232407742.25708]   \n",
      "best: {'colsample_bytree': np.float64(0.7708404052529336), 'learning_rate': np.float64(0.09250674132536013), 'max_depth': np.float64(9.0), 'min_child_weight': np.float64(2.0)}\n"
     ]
    }
   ],
   "execution_count": 24,
   "source": [
    "def objective_func(search_space):\n",
    "    xgb_reg = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=int(search_space['max_depth']),\n",
    "        min_child_weight=int(search_space['min_child_weight']),\n",
    "        learning_rate=search_space['learning_rate'],\n",
    "        colsample_bytree=search_space['colsample_bytree'],\n",
    "        random_state=123\n",
    "    )\n",
    "    mse = cross_val_score(xgb_reg, train_x, train_y, scoring='neg_mean_squared_error', cv=3)\n",
    "    mse = -1.0* np.mean(mse)\n",
    "\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(\n",
    "    fn=objective_func,\n",
    "    space=xgb_search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=500,\n",
    "    trials=trial_val,\n",
    "    rstate=np.random.default_rng(seed=9)\n",
    ")\n",
    "\n",
    "print('best:', best)\n"
   ],
   "id": "79dbe95ca3d3b928"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f875d9c2ce04bea8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### best param\n",
    "\n",
    "colsample_bytree = 0.77084\n",
    "learning_rate = 0.0925\n",
    "max_depth = 9\n",
    "min_child_weight = 2\n"
   ],
   "id": "af094db918e3d40b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T05:59:42.617775Z",
     "start_time": "2024-09-13T05:59:42.614579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_reg = xgb.XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        min_child_weight=2,\n",
    "        learning_rate=0.09025,\n",
    "        random_state=123\n",
    "    )"
   ],
   "id": "9cc2e60d6d658acf",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T05:59:43.412519Z",
     "start_time": "2024-09-13T05:59:42.978959Z"
    }
   },
   "cell_type": "code",
   "source": "model = xgb_reg.fit(train_x,train_y)",
   "id": "cf1a0b064576888f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T05:59:43.421229Z",
     "start_time": "2024-09-13T05:59:43.413889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_predictions = model.predict(test_x)\n",
    "test_mse = mean_squared_error(test_y, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(test_y, test_predictions)\n",
    "\n",
    "print(\"테스트 세트 성능:\")\n",
    "print(\"RMSE:\", test_rmse)\n",
    "print(\"R2:\", test_r2)"
   ],
   "id": "4bfb633fb38ad8b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 성능:\n",
      "RMSE: 48130.51395498043\n",
      "R2: 0.8316832763688611\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b95de5749057cd8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
