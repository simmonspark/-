{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print('-------------------')\n",
    "print('|     lab1         |')\n",
    "print('-------------------')\n",
    "\n",
    "# 데이터 다운로드 및 추출\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz\"\n",
    "urllib.request.urlretrieve(url, \"housing.tgz\")\n",
    "\n",
    "tar = tarfile.open(\"housing.tgz\")\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# 데이터 로드\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "print(housing.describe())\n",
    "print(housing.info())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:00:35.126584Z",
     "start_time": "2024-09-19T06:00:33.870722Z"
    }
   },
   "id": "dd249bfe19f7496b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "|     lab1         |\n",
      "-------------------\n",
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "housing\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:00:35.135840Z",
     "start_time": "2024-09-19T06:00:35.127427Z"
    }
   },
   "id": "8e6e68dc0adedb4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                41.0        880.0           129.0   \n",
       "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2        -122.24     37.85                52.0       1467.0           190.0   \n",
       "3        -122.25     37.85                52.0       1274.0           235.0   \n",
       "4        -122.25     37.85                52.0       1627.0           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
       "20636    -121.21     39.49                18.0        697.0           150.0   \n",
       "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
       "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
       "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0           322.0       126.0         8.3252            452600.0   \n",
       "1          2401.0      1138.0         8.3014            358500.0   \n",
       "2           496.0       177.0         7.2574            352100.0   \n",
       "3           558.0       219.0         5.6431            341300.0   \n",
       "4           565.0       259.0         3.8462            342200.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635       845.0       330.0         1.5603             78100.0   \n",
       "20636       356.0       114.0         2.5568             77100.0   \n",
       "20637      1007.0       433.0         1.7000             92300.0   \n",
       "20638       741.0       349.0         1.8672             84700.0   \n",
       "20639      1387.0       530.0         2.3886             89400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-121.09</td>\n",
       "      <td>39.48</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-121.21</td>\n",
       "      <td>39.49</td>\n",
       "      <td>18.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-121.22</td>\n",
       "      <td>39.43</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-121.32</td>\n",
       "      <td>39.43</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-121.24</td>\n",
       "      <td>39.37</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 이상치 탐지\n",
    "\n",
    "1. iqr 값을 계산해서 각 이상치 값이 있는 데이터의 인덱스를 찾아낸다.\n",
    "2. 인덱스의 중복을 set으로 제거한 후, 데이터에서 인덱스를 제거한다.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "921066d80fc9a2cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:00:35.140730Z",
     "start_time": "2024-09-19T06:00:35.136867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def AnomalyDelete(df: pd.DataFrame):\n",
    "    col = df.columns[:-1]\n",
    "    stack = []\n",
    "\n",
    "    quantile_25 = df[col].quantile(0.25)\n",
    "    quantile_75 = df[col].quantile(0.75)\n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * 1.5\n",
    "\n",
    "    for i in col:\n",
    "        lowest_val = quantile_25[i] - iqr_weight[i]\n",
    "        highest_val = quantile_75[i] + iqr_weight[i]\n",
    "        outlier_idx = df[(df[i] < lowest_val) | (df[i] > highest_val)].index\n",
    "        stack.extend(outlier_idx)\n",
    "\n",
    "    return list(set(stack))\n",
    "\n",
    "\n",
    "def delHandler(X_train: pd.DataFrame, y_train: pd.Series, idxs):\n",
    "    X_train = X_train.drop(index=idxs, axis=0)\n",
    "    y_train = y_train.drop(index=idxs, axis=0)\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def AnomalyHandler(X_train: pd.DataFrame, y_train):\n",
    "    idxs = AnomalyDelete(X_train)\n",
    "    X_train, y_train = delHandler(X_train, y_train, idxs)\n",
    "    return X_train, y_train"
   ],
   "id": "c88a20ac1d63c846",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 전처리\n",
    "1. label 인코딩을 진행한다.\n",
    "2. 스탠다드 스케일링을 진행한다.\n",
    "3. train_df의 경우에는 fit_transform, test데이터는 transform을 진행한다. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "874efeaa79745c14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:00:35.147456Z",
     "start_time": "2024-09-19T06:00:35.143787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CombinedAttributesAdder():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.sk = StandardScaler()\n",
    "\n",
    "    def fit_and_transform(self, train_df, test_df):\n",
    "        train_df, test_df = self._DataHandler(train_df, test_df)\n",
    "        return train_df, test_df\n",
    "\n",
    "    def _Encoder(self, train_df, test_df):\n",
    "        feature = 'ocean_proximity'\n",
    "        train_df[feature] = self.le.fit_transform(train_df[feature])\n",
    "        test_df[feature] = self.le.transform(test_df[feature])\n",
    "        return train_df, test_df\n",
    "\n",
    "    def _Norm(self, train_df, test_df):\n",
    "        numeric_features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "                            'total_bedrooms', 'population', 'households']\n",
    "        for feature in numeric_features:\n",
    "            train_df[feature] = self.sk.fit_transform(train_df[[feature]])\n",
    "            test_df[feature] = self.sk.transform(test_df[[feature]])\n",
    "        return train_df, test_df\n",
    "\n",
    "    def _DataHandler(self, train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "        train_df, test_df = self._Encoder(train_df, test_df)\n",
    "        train_df, test_df = self._Norm(train_df, test_df)\n",
    "        return train_df, test_df"
   ],
   "id": "78a5226fa6707ab3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:00:35.168228Z",
     "start_time": "2024-09-19T06:00:35.148764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "housing = housing.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_df = housing.iloc[:18000].copy()\n",
    "test_df = housing.iloc[18000:].copy()\n",
    "\n",
    "handler = CombinedAttributesAdder()\n",
    "train_df, test_df = handler.fit_and_transform(train_df=train_df, test_df=test_df)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ],
   "id": "3b7d47d490b350c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0   1.234933 -1.375096            0.428748    -0.534476       -0.642579   \n",
      "1   0.680907 -0.705833            1.858687    -0.483703       -0.265257   \n",
      "2  -1.694917  2.406475            0.031543    -0.457631       -0.571386   \n",
      "3   0.526179 -0.668392            0.508189    -0.468151       -0.545282   \n",
      "4  -1.625040  1.367479           -1.636720     1.624975        1.305730   \n",
      "\n",
      "   population  households  median_income  median_house_value  ocean_proximity  \n",
      "0   -0.347003   -0.607841         3.4583            112700.0                4  \n",
      "1    0.031940   -0.244467         3.3326            167600.0                0  \n",
      "2   -0.591425   -0.599998         3.2891             93100.0                1  \n",
      "3   -0.506141   -0.443146         4.1806            209000.0                0  \n",
      "4    1.355162    1.308365         3.8616            195100.0                0  \n",
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "18000   0.850609 -0.878999           -1.795602    -0.490564        0.145288   \n",
      "18001   0.675916 -0.724554           -0.206781    -0.029034        0.638891   \n",
      "18002   1.155074 -1.173849           -1.636720     2.705387        2.133939   \n",
      "18003   1.249907 -1.365736           -0.603986    -0.353798       -0.355435   \n",
      "18004   0.825653 -0.827517           -0.206781    -0.156195        0.076468   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "18000    1.522213    0.338498         2.9271            123200.0   \n",
      "18001    1.527488    0.790754         1.9495            173200.0   \n",
      "18002    1.678714    2.152750         5.3110            255800.0   \n",
      "18003    0.063592   -0.288909         3.8194            125700.0   \n",
      "18004   -0.009383    0.071850         2.4732            165800.0   \n",
      "\n",
      "       ocean_proximity  \n",
      "18000                0  \n",
      "18001                0  \n",
      "18002                4  \n",
      "18003                4  \n",
      "18004                0  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:00:35.188720Z",
     "start_time": "2024-09-19T06:00:35.169445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_x = train_df.drop(['median_house_value'], axis=1)\n",
    "test_x = test_df.drop(['median_house_value'], axis=1)\n",
    "\n",
    "train_y = train_df['median_house_value']\n",
    "test_y = test_df['median_house_value']\n",
    "\n",
    "train_x, train_y = AnomalyHandler(train_x, train_y)\n",
    "\n",
    "train_x[\"income_cat\"] = pd.cut(train_df[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "test_x[\"income_cat\"] = pd.cut(test_df[\"median_income\"],\n",
    "                              bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                              labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "train_x = pd.get_dummies(train_x, columns=['income_cat'])\n",
    "test_x = pd.get_dummies(test_x, columns=['income_cat'])"
   ],
   "id": "cc787c307566a939",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GridSearchCV를 이용한 하이퍼파라미터 최적화"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee1e9d01c57a05a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:14.205603Z",
     "start_time": "2024-09-19T06:00:35.189756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_reg = xgb.XGBRegressor(random_state=123)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [5, 7, 10],\n",
    "}\n",
    "grid_search = GridSearchCV(xgb_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(train_x, train_y)\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "test_predictions = best_model.predict(test_x)\n",
    "test_mse = mean_squared_error(test_y, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(test_y, test_predictions)\n",
    "\n",
    "print(\"테스트 세트 성능:\")\n",
    "print(\"RMSE:\", test_rmse)\n",
    "print(\"R2:\", test_r2)"
   ],
   "id": "83343e47adfed5b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END .learning_rate=0.01, max_depth=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.3, max_depth=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.3, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "테스트 세트 성능:\n",
      "RMSE: 49419.666075540576\n",
      "R2: 0.8166897341466138\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:14.209219Z",
     "start_time": "2024-09-19T06:01:14.207122Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "851c8de2653d05d2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 베이지안 최적화로 object function optimize"
   ],
   "id": "db3559f8f510ba22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:14.346445Z",
     "start_time": "2024-09-19T06:01:14.210189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from hyperopt import hp\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import STATUS_OK, fmin, tpe, Trials\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_search_space = {\n",
    "    'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "}"
   ],
   "id": "744a97c720de173",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:46.750120Z",
     "start_time": "2024-09-19T06:01:14.348975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective_func(search_space):\n",
    "    xgb_reg = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=int(search_space['max_depth']),\n",
    "        min_child_weight=int(search_space['min_child_weight']),\n",
    "        learning_rate=search_space['learning_rate'],\n",
    "        colsample_bytree=search_space['colsample_bytree'],\n",
    "        random_state=123\n",
    "    )\n",
    "    mse = cross_val_score(xgb_reg, train_x, train_y, scoring='neg_mean_squared_error', cv=3)\n",
    "    mse = -1.0 * np.mean(mse)\n",
    "\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(\n",
    "    fn=objective_func,\n",
    "    space=xgb_search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trial_val,\n",
    "    rstate=np.random.default_rng(seed=9)\n",
    ")\n",
    "\n",
    "print('best:', best)\n"
   ],
   "id": "79dbe95ca3d3b928",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:32<00:00,  1.62s/trial, best loss: 2270824682.5156717]\n",
      "best: {'colsample_bytree': np.float64(0.8637740285716389), 'learning_rate': np.float64(0.10657919742273766), 'max_depth': np.float64(8.0), 'min_child_weight': np.float64(2.0)}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:46.752717Z",
     "start_time": "2024-09-19T06:01:46.751235Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "f875d9c2ce04bea8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### best param\n",
    "\n",
    "colsample_bytree = 0.77084\n",
    "learning_rate = 0.0925\n",
    "max_depth = 9\n",
    "min_child_weight = 2\n"
   ],
   "id": "af094db918e3d40b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:46.755802Z",
     "start_time": "2024-09-19T06:01:46.753676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_reg = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    min_child_weight=2,\n",
    "    learning_rate=0.09025,\n",
    "    random_state=123\n",
    ")"
   ],
   "id": "9cc2e60d6d658acf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:47.177351Z",
     "start_time": "2024-09-19T06:01:46.757610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = xgb_reg.fit(train_x, train_y)"
   ],
   "id": "cf1a0b064576888f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:47.186797Z",
     "start_time": "2024-09-19T06:01:47.178271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_predictions = model.predict(test_x)\n",
    "test_mse = mean_squared_error(test_y, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(test_y, test_predictions)\n",
    "\n",
    "print(\"테스트 세트 성능:\")\n",
    "print(\"RMSE:\", test_rmse)\n",
    "print(\"R2:\", test_r2)"
   ],
   "id": "4bfb633fb38ad8b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 성능:\n",
      "RMSE: 49346.21488033891\n",
      "R2: 0.8172342280018438\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:01:47.451157Z",
     "start_time": "2024-09-19T06:01:47.187672Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9b95de5749057cd8",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m confusion_matrix\n\u001B[0;32m----> 3\u001B[0m \u001B[43mconfusion_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_predictions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/forml/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/forml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:342\u001B[0m, in \u001B[0;36mconfusion_matrix\u001B[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m    248\u001B[0m     {\n\u001B[1;32m    249\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    258\u001B[0m     y_true, y_pred, \u001B[38;5;241m*\u001B[39m, labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    259\u001B[0m ):\n\u001B[1;32m    260\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001B[39;00m\n\u001B[1;32m    261\u001B[0m \n\u001B[1;32m    262\u001B[0m \u001B[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;124;03m    (0, 2, 1, 1)\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    344\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m y_type)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/forml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:112\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m    109\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 112\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    113\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    114\u001B[0m             type_true, type_pred\n\u001B[1;32m    115\u001B[0m         )\n\u001B[1;32m    116\u001B[0m     )\n\u001B[1;32m    118\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[1;32m    119\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[0;31mValueError\u001B[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T06:02:15.536914Z",
     "start_time": "2024-09-19T06:02:15.532758Z"
    }
   },
   "cell_type": "code",
   "source": "test_y\n",
   "id": "e820b886162e8f47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000    123200.0\n",
       "18001    173200.0\n",
       "18002    255800.0\n",
       "18003    125700.0\n",
       "18004    165800.0\n",
       "           ...   \n",
       "20635    286300.0\n",
       "20636    251900.0\n",
       "20637     99800.0\n",
       "20638    147400.0\n",
       "20639    137500.0\n",
       "Name: median_house_value, Length: 2640, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b4ea490f8ca0280"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
