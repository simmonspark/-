{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:52.611737634Z",
     "start_time": "2024-09-12T07:14:52.610738703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "|     lab1         |\n",
      "-------------------\n",
      "data already exist\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "import urllib.request\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "print('-------------------')\n",
    "print('|     lab1         |')\n",
    "print('-------------------')\n",
    "\n",
    "if os.path.exists('/semi.csv'):\n",
    "    '''\n",
    "    혹시 파일이 생기지 않는다면, 아래 두 줄의 스크립스틑 파이썬 .py파일로 만들어서 실행하면 됩니다. \n",
    "    '''\n",
    "    url = \"https://drive.google.com/uc?export=download&id=1XCU0eo2xZ03xhxJhdrCnVjduCoaBQ7kJ\"\n",
    "    urllib.request.urlretrieve(url, \"semi.csv\")  # save in a file\n",
    "else:\n",
    "    print('data already exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('semi.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:52.662789687Z",
     "start_time": "2024-09-12T07:14:52.611131050Z"
    }
   },
   "id": "fc9a8e247249f5b1",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Time          0\n0             6\n1             7\n2            14\n3            14\n             ..\n586           1\n587           1\n588           1\n589           1\nPass/Fail     0\nLength: 592, dtype: int64"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:52.663361686Z",
     "start_time": "2024-09-12T07:14:52.659019061Z"
    }
   },
   "id": "e242cdf0bf233491",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 592 entries, Time to Pass/Fail\n",
      "dtypes: float64(590), int64(1), object(1)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:52.683726530Z",
     "start_time": "2024-09-12T07:14:52.663447928Z"
    }
   },
   "id": "17467ff15d1140b7",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                 0            1            2            3            4  \\\ncount  1561.000000  1560.000000  1553.000000  1553.000000  1553.000000   \nmean   3014.452896  2495.850231  2200.547318  1396.376627     4.197013   \nstd      73.621787    80.407705    29.513152   441.691640    56.355540   \nmin    2743.240000  2158.750000  2060.660000     0.000000     0.681500   \n25%    2966.260000  2452.247500  2181.044400  1081.875800     1.017700   \n50%    3011.490000  2499.405000  2201.066700  1285.214400     1.316800   \n75%    3056.650000  2538.822500  2218.055500  1591.223500     1.525700   \nmax    3356.350000  2846.440000  2315.266700  3715.041700  1114.536600   \n\n            5            6            7            8            9  ...  \\\ncount  1553.0  1553.000000  1558.000000  1565.000000  1565.000000  ...   \nmean    100.0   101.112908     0.121822     1.462862    -0.000841  ...   \nstd       0.0     6.237214     0.008961     0.073897     0.015116  ...   \nmin     100.0    82.131100     0.000000     1.191000    -0.053400  ...   \n25%     100.0    97.920000     0.121100     1.411200    -0.010800  ...   \n50%     100.0   101.512200     0.122400     1.461600    -0.001300  ...   \n75%     100.0   104.586700     0.123800     1.516900     0.008400  ...   \nmax     100.0   129.252200     0.128600     1.656400     0.074900  ...   \n\n              581          582          583          584          585  \\\ncount  618.000000  1566.000000  1566.000000  1566.000000  1566.000000   \nmean    97.934373     0.500096     0.015318     0.003847     3.067826   \nstd     87.520966     0.003404     0.017180     0.003720     3.578033   \nmin      0.000000     0.477800     0.006000     0.001700     1.197500   \n25%     46.184900     0.497900     0.011600     0.003100     2.306500   \n50%     72.288900     0.500200     0.013800     0.003600     2.757650   \n75%    116.539150     0.502375     0.016500     0.004100     3.295175   \nmax    737.304800     0.509800     0.476600     0.104500    99.303200   \n\n               586          587          588          589    Pass/Fail  \ncount  1566.000000  1566.000000  1566.000000  1566.000000  1567.000000  \nmean      0.021458     0.016475     0.005283    99.670066    -0.867262  \nstd       0.012358     0.008808     0.002867    93.891919     0.498010  \nmin      -0.016900     0.003200     0.001000     0.000000    -1.000000  \n25%       0.013425     0.010600     0.003300    44.368600    -1.000000  \n50%       0.020500     0.014800     0.004600    71.900500    -1.000000  \n75%       0.027600     0.020300     0.006400   114.749700    -1.000000  \nmax       0.102800     0.079900     0.028600   737.304800     1.000000  \n\n[8 rows x 591 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>581</th>\n      <th>582</th>\n      <th>583</th>\n      <th>584</th>\n      <th>585</th>\n      <th>586</th>\n      <th>587</th>\n      <th>588</th>\n      <th>589</th>\n      <th>Pass/Fail</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1561.000000</td>\n      <td>1560.000000</td>\n      <td>1553.000000</td>\n      <td>1553.000000</td>\n      <td>1553.000000</td>\n      <td>1553.0</td>\n      <td>1553.000000</td>\n      <td>1558.000000</td>\n      <td>1565.000000</td>\n      <td>1565.000000</td>\n      <td>...</td>\n      <td>618.000000</td>\n      <td>1566.000000</td>\n      <td>1566.000000</td>\n      <td>1566.000000</td>\n      <td>1566.000000</td>\n      <td>1566.000000</td>\n      <td>1566.000000</td>\n      <td>1566.000000</td>\n      <td>1566.000000</td>\n      <td>1567.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3014.452896</td>\n      <td>2495.850231</td>\n      <td>2200.547318</td>\n      <td>1396.376627</td>\n      <td>4.197013</td>\n      <td>100.0</td>\n      <td>101.112908</td>\n      <td>0.121822</td>\n      <td>1.462862</td>\n      <td>-0.000841</td>\n      <td>...</td>\n      <td>97.934373</td>\n      <td>0.500096</td>\n      <td>0.015318</td>\n      <td>0.003847</td>\n      <td>3.067826</td>\n      <td>0.021458</td>\n      <td>0.016475</td>\n      <td>0.005283</td>\n      <td>99.670066</td>\n      <td>-0.867262</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>73.621787</td>\n      <td>80.407705</td>\n      <td>29.513152</td>\n      <td>441.691640</td>\n      <td>56.355540</td>\n      <td>0.0</td>\n      <td>6.237214</td>\n      <td>0.008961</td>\n      <td>0.073897</td>\n      <td>0.015116</td>\n      <td>...</td>\n      <td>87.520966</td>\n      <td>0.003404</td>\n      <td>0.017180</td>\n      <td>0.003720</td>\n      <td>3.578033</td>\n      <td>0.012358</td>\n      <td>0.008808</td>\n      <td>0.002867</td>\n      <td>93.891919</td>\n      <td>0.498010</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2743.240000</td>\n      <td>2158.750000</td>\n      <td>2060.660000</td>\n      <td>0.000000</td>\n      <td>0.681500</td>\n      <td>100.0</td>\n      <td>82.131100</td>\n      <td>0.000000</td>\n      <td>1.191000</td>\n      <td>-0.053400</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.477800</td>\n      <td>0.006000</td>\n      <td>0.001700</td>\n      <td>1.197500</td>\n      <td>-0.016900</td>\n      <td>0.003200</td>\n      <td>0.001000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2966.260000</td>\n      <td>2452.247500</td>\n      <td>2181.044400</td>\n      <td>1081.875800</td>\n      <td>1.017700</td>\n      <td>100.0</td>\n      <td>97.920000</td>\n      <td>0.121100</td>\n      <td>1.411200</td>\n      <td>-0.010800</td>\n      <td>...</td>\n      <td>46.184900</td>\n      <td>0.497900</td>\n      <td>0.011600</td>\n      <td>0.003100</td>\n      <td>2.306500</td>\n      <td>0.013425</td>\n      <td>0.010600</td>\n      <td>0.003300</td>\n      <td>44.368600</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3011.490000</td>\n      <td>2499.405000</td>\n      <td>2201.066700</td>\n      <td>1285.214400</td>\n      <td>1.316800</td>\n      <td>100.0</td>\n      <td>101.512200</td>\n      <td>0.122400</td>\n      <td>1.461600</td>\n      <td>-0.001300</td>\n      <td>...</td>\n      <td>72.288900</td>\n      <td>0.500200</td>\n      <td>0.013800</td>\n      <td>0.003600</td>\n      <td>2.757650</td>\n      <td>0.020500</td>\n      <td>0.014800</td>\n      <td>0.004600</td>\n      <td>71.900500</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3056.650000</td>\n      <td>2538.822500</td>\n      <td>2218.055500</td>\n      <td>1591.223500</td>\n      <td>1.525700</td>\n      <td>100.0</td>\n      <td>104.586700</td>\n      <td>0.123800</td>\n      <td>1.516900</td>\n      <td>0.008400</td>\n      <td>...</td>\n      <td>116.539150</td>\n      <td>0.502375</td>\n      <td>0.016500</td>\n      <td>0.004100</td>\n      <td>3.295175</td>\n      <td>0.027600</td>\n      <td>0.020300</td>\n      <td>0.006400</td>\n      <td>114.749700</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3356.350000</td>\n      <td>2846.440000</td>\n      <td>2315.266700</td>\n      <td>3715.041700</td>\n      <td>1114.536600</td>\n      <td>100.0</td>\n      <td>129.252200</td>\n      <td>0.128600</td>\n      <td>1.656400</td>\n      <td>0.074900</td>\n      <td>...</td>\n      <td>737.304800</td>\n      <td>0.509800</td>\n      <td>0.476600</td>\n      <td>0.104500</td>\n      <td>99.303200</td>\n      <td>0.102800</td>\n      <td>0.079900</td>\n      <td>0.028600</td>\n      <td>737.304800</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 591 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:53.036105242Z",
     "start_time": "2024-09-12T07:14:52.675021627Z"
    }
   },
   "id": "47c6a2bf498b0abb",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL PASSED!\n",
      "\n",
      "duplicated! 52\n",
      "duplicated! 69\n",
      "duplicated! 97\n",
      "duplicated! 141\n",
      "duplicated! 149\n",
      "duplicated! 178\n",
      "duplicated! 179\n",
      "duplicated! 186\n",
      "duplicated! 189\n",
      "duplicated! 190\n",
      "duplicated! 191\n",
      "duplicated! 192\n",
      "duplicated! 193\n",
      "duplicated! 194\n",
      "duplicated! 226\n",
      "duplicated! 229\n",
      "duplicated! 230\n",
      "duplicated! 231\n",
      "duplicated! 232\n",
      "duplicated! 233\n",
      "duplicated! 234\n",
      "duplicated! 235\n",
      "duplicated! 236\n",
      "duplicated! 237\n",
      "duplicated! 240\n",
      "duplicated! 241\n",
      "duplicated! 242\n",
      "duplicated! 243\n",
      "duplicated! 256\n",
      "duplicated! 257\n",
      "duplicated! 258\n",
      "duplicated! 259\n",
      "duplicated! 260\n",
      "duplicated! 261\n",
      "duplicated! 262\n",
      "duplicated! 263\n",
      "duplicated! 264\n",
      "duplicated! 265\n",
      "duplicated! 266\n",
      "duplicated! 276\n",
      "duplicated! 284\n",
      "duplicated! 313\n",
      "duplicated! 314\n",
      "duplicated! 315\n",
      "duplicated! 322\n",
      "duplicated! 325\n",
      "duplicated! 326\n",
      "duplicated! 327\n",
      "duplicated! 328\n",
      "duplicated! 329\n",
      "duplicated! 330\n",
      "duplicated! 364\n",
      "duplicated! 369\n",
      "duplicated! 370\n",
      "duplicated! 371\n",
      "duplicated! 372\n",
      "duplicated! 373\n",
      "duplicated! 374\n",
      "duplicated! 375\n",
      "duplicated! 378\n",
      "duplicated! 379\n",
      "duplicated! 380\n",
      "duplicated! 381\n",
      "duplicated! 394\n",
      "duplicated! 395\n",
      "duplicated! 396\n",
      "duplicated! 397\n",
      "duplicated! 398\n",
      "duplicated! 399\n",
      "duplicated! 400\n",
      "duplicated! 401\n",
      "duplicated! 402\n",
      "duplicated! 403\n",
      "duplicated! 404\n",
      "duplicated! 414\n",
      "duplicated! 422\n",
      "duplicated! 449\n",
      "duplicated! 450\n",
      "duplicated! 451\n",
      "duplicated! 458\n",
      "duplicated! 461\n",
      "duplicated! 462\n",
      "duplicated! 463\n",
      "duplicated! 464\n",
      "duplicated! 465\n",
      "duplicated! 466\n",
      "duplicated! 481\n",
      "duplicated! 498\n",
      "duplicated! 501\n",
      "duplicated! 502\n",
      "duplicated! 503\n",
      "duplicated! 504\n",
      "duplicated! 505\n",
      "duplicated! 506\n",
      "duplicated! 507\n",
      "duplicated! 508\n",
      "duplicated! 509\n",
      "duplicated! 512\n",
      "duplicated! 513\n",
      "duplicated! 514\n",
      "duplicated! 515\n",
      "duplicated! 528\n",
      "duplicated! 529\n",
      "duplicated! 530\n",
      "duplicated! 531\n",
      "duplicated! 532\n",
      "duplicated! 533\n",
      "duplicated! 534\n",
      "duplicated! 535\n",
      "duplicated! 536\n",
      "duplicated! 537\n",
      "duplicated! 538\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def NullHandler(df: pd.DataFrame):\n",
    "    features = range(590)\n",
    "    for fe in features:\n",
    "        if df[str(fe)].isnull().sum() != 0:\n",
    "            df[str(fe)] = df[str(fe)].fillna(np.mean(df[str(fe)]))\n",
    "    assert df.isnull().sum().sum() == 0\n",
    "    print('NULL PASSED!\\n')\n",
    "    return df\n",
    "\n",
    "\n",
    "def DuplicatedHandler(df: pd.DataFrame):\n",
    "    features = range(590)\n",
    "    stack = []\n",
    "    idx = []\n",
    "    for i,fe in enumerate(features):\n",
    "        st = df[str(fe)].std()\n",
    "        me = df[str(fe)].mean()\n",
    "        mx = df[str(fe)].max()\n",
    "        mn = df[str(fe)].mean()\n",
    "        if (st, me, mx, mn) in stack:\n",
    "            idx.append(fe)\n",
    "            print('duplicated!',i)\n",
    "        else:\n",
    "            stack.append((st, me, mx, mn))\n",
    "\n",
    "    for i in idx:\n",
    "        df = df.drop(str(i), axis=1)\n",
    "    df = df.drop(['Time'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def Norm(df: pd.DataFrame):\n",
    "    numeric_features = df.columns[:-1]\n",
    "\n",
    "    for feature in numeric_features:\n",
    "        sk = StandardScaler()\n",
    "        df[feature] = sk.fit_transform(df[[feature]])\n",
    "    return df\n",
    "\n",
    "\n",
    "def DataHandler(df: pd.DataFrame):\n",
    "    df = NullHandler(df)\n",
    "    df = DuplicatedHandler(df)\n",
    "    df = Norm(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = DataHandler(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:54.128210519Z",
     "start_time": "2024-09-12T07:14:53.039332031Z"
    }
   },
   "id": "11c7f82bfd7aeb81",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis NaN data check : \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39misna()\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39msum())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print('is NaN data check : ', df.isna().sum().sum())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:22:22.350464498Z",
     "start_time": "2024-09-12T07:22:22.122589048Z"
    }
   },
   "id": "f2920a3392e3ba84",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4    5         6  \\\n0     0.224309  0.849725 -0.436273  0.033555 -0.050580  0.0 -0.563790   \n1     1.107136 -0.382910  1.017137  0.153067 -0.060045  0.0  0.198217   \n2    -1.114158  0.799102 -0.481289  0.686213 -0.047906  0.0 -0.906210   \n3    -0.350312 -0.198875 -0.051547 -1.106948 -0.051290  0.0  0.503246   \n4     0.242143  0.087526  1.117387 -0.158919 -0.047492  0.0 -0.115382   \n...        ...       ...       ...       ...       ...  ...       ...   \n1562 -1.566122 -0.392636 -0.708645  3.842373 -0.048368  0.0 -3.039363   \n1563  0.515363  0.332906 -0.067433 -0.618139 -0.059208  0.0 -0.425952   \n1564 -0.485220 -1.447220  0.195859 -0.650359 -0.060148  0.0 -0.273986   \n1565 -1.627246  0.450858 -0.800571 -0.483761 -0.046793  0.0 -0.372966   \n1566 -0.946577 -0.562207 -0.173737  3.452906 -0.046344  0.0 -2.579517   \n\n             7         8         9  ...           581       582        583  \\\n0     0.266269  0.509826  1.128417  ...  2.587617e-16  0.118699  -0.204890   \n1     0.322244  0.456999  0.022582  ...  2.007880e+00  0.530203   0.406679   \n2     0.255074 -0.260907  0.327183  ... -2.744816e-01 -1.262780   0.022264   \n3    -0.013602  0.343218 -0.765408  ... -4.386698e-01 -0.322199  -0.292257   \n4     0.187905  0.545044 -0.149584  ...  2.587617e-16 -5.906899  26.867231   \n...        ...       ...       ...  ...           ...       ...        ...   \n1562  0.333438 -1.631702 -0.242289  ...  1.916244e+00 -0.380985  -0.059279   \n1563 -0.147940 -0.400425 -0.348237  ...  2.587617e-16 -0.763096  -0.129172   \n1564 -0.114356  0.000000  0.000000  ... -9.907605e-01 -0.410378  -0.001034   \n1565 -0.058381 -0.008962 -0.421077  ... -8.085176e-02  0.089306   0.144578   \n1566  0.187905  0.000000  0.000000  ...  7.256186e-01 -0.410378   0.162051   \n\n            584        585       586       587           588           589  \\\n0     -0.093207  -0.197113  0.000000  0.000000 -3.027186e-16  1.514500e-16   \n1      0.444706   0.385059 -0.960174  0.411853  2.501244e-01  1.156689e+00   \n2      0.014375   0.029833  2.991151  3.627063  3.321419e+00 -1.791486e-01   \n3     -0.362164  -0.283417 -0.101895 -0.178927 -3.082928e-01 -2.752459e-01   \n4     27.071425  26.913347 -0.101895 -0.178927 -3.082928e-01 -2.752459e-01   \n...         ...        ...       ...       ...           ...           ...   \n1562   0.014375  -0.056191 -1.186890 -0.303900 -2.035896e-01  1.103056e+00   \n1563  -0.066312  -0.124177 -1.186890 -0.303900 -2.035896e-01  1.103056e+00   \n1564   0.068167  -0.002468 -0.142380 -0.894681 -9.714133e-01 -5.983777e-01   \n1565  -0.012520   0.139376  0.383924  0.911745  7.736405e-01 -6.581942e-02   \n1566   0.041271   0.156519 -0.790138 -0.031232 -2.733918e-01  4.061977e-01   \n\n      Pass/Fail  \n0            -1  \n1            -1  \n2             1  \n3            -1  \n4            -1  \n...         ...  \n1562         -1  \n1563         -1  \n1564         -1  \n1565         -1  \n1566         -1  \n\n[1567 rows x 479 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>581</th>\n      <th>582</th>\n      <th>583</th>\n      <th>584</th>\n      <th>585</th>\n      <th>586</th>\n      <th>587</th>\n      <th>588</th>\n      <th>589</th>\n      <th>Pass/Fail</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.224309</td>\n      <td>0.849725</td>\n      <td>-0.436273</td>\n      <td>0.033555</td>\n      <td>-0.050580</td>\n      <td>0.0</td>\n      <td>-0.563790</td>\n      <td>0.266269</td>\n      <td>0.509826</td>\n      <td>1.128417</td>\n      <td>...</td>\n      <td>2.587617e-16</td>\n      <td>0.118699</td>\n      <td>-0.204890</td>\n      <td>-0.093207</td>\n      <td>-0.197113</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-3.027186e-16</td>\n      <td>1.514500e-16</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.107136</td>\n      <td>-0.382910</td>\n      <td>1.017137</td>\n      <td>0.153067</td>\n      <td>-0.060045</td>\n      <td>0.0</td>\n      <td>0.198217</td>\n      <td>0.322244</td>\n      <td>0.456999</td>\n      <td>0.022582</td>\n      <td>...</td>\n      <td>2.007880e+00</td>\n      <td>0.530203</td>\n      <td>0.406679</td>\n      <td>0.444706</td>\n      <td>0.385059</td>\n      <td>-0.960174</td>\n      <td>0.411853</td>\n      <td>2.501244e-01</td>\n      <td>1.156689e+00</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.114158</td>\n      <td>0.799102</td>\n      <td>-0.481289</td>\n      <td>0.686213</td>\n      <td>-0.047906</td>\n      <td>0.0</td>\n      <td>-0.906210</td>\n      <td>0.255074</td>\n      <td>-0.260907</td>\n      <td>0.327183</td>\n      <td>...</td>\n      <td>-2.744816e-01</td>\n      <td>-1.262780</td>\n      <td>0.022264</td>\n      <td>0.014375</td>\n      <td>0.029833</td>\n      <td>2.991151</td>\n      <td>3.627063</td>\n      <td>3.321419e+00</td>\n      <td>-1.791486e-01</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.350312</td>\n      <td>-0.198875</td>\n      <td>-0.051547</td>\n      <td>-1.106948</td>\n      <td>-0.051290</td>\n      <td>0.0</td>\n      <td>0.503246</td>\n      <td>-0.013602</td>\n      <td>0.343218</td>\n      <td>-0.765408</td>\n      <td>...</td>\n      <td>-4.386698e-01</td>\n      <td>-0.322199</td>\n      <td>-0.292257</td>\n      <td>-0.362164</td>\n      <td>-0.283417</td>\n      <td>-0.101895</td>\n      <td>-0.178927</td>\n      <td>-3.082928e-01</td>\n      <td>-2.752459e-01</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.242143</td>\n      <td>0.087526</td>\n      <td>1.117387</td>\n      <td>-0.158919</td>\n      <td>-0.047492</td>\n      <td>0.0</td>\n      <td>-0.115382</td>\n      <td>0.187905</td>\n      <td>0.545044</td>\n      <td>-0.149584</td>\n      <td>...</td>\n      <td>2.587617e-16</td>\n      <td>-5.906899</td>\n      <td>26.867231</td>\n      <td>27.071425</td>\n      <td>26.913347</td>\n      <td>-0.101895</td>\n      <td>-0.178927</td>\n      <td>-3.082928e-01</td>\n      <td>-2.752459e-01</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1562</th>\n      <td>-1.566122</td>\n      <td>-0.392636</td>\n      <td>-0.708645</td>\n      <td>3.842373</td>\n      <td>-0.048368</td>\n      <td>0.0</td>\n      <td>-3.039363</td>\n      <td>0.333438</td>\n      <td>-1.631702</td>\n      <td>-0.242289</td>\n      <td>...</td>\n      <td>1.916244e+00</td>\n      <td>-0.380985</td>\n      <td>-0.059279</td>\n      <td>0.014375</td>\n      <td>-0.056191</td>\n      <td>-1.186890</td>\n      <td>-0.303900</td>\n      <td>-2.035896e-01</td>\n      <td>1.103056e+00</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1563</th>\n      <td>0.515363</td>\n      <td>0.332906</td>\n      <td>-0.067433</td>\n      <td>-0.618139</td>\n      <td>-0.059208</td>\n      <td>0.0</td>\n      <td>-0.425952</td>\n      <td>-0.147940</td>\n      <td>-0.400425</td>\n      <td>-0.348237</td>\n      <td>...</td>\n      <td>2.587617e-16</td>\n      <td>-0.763096</td>\n      <td>-0.129172</td>\n      <td>-0.066312</td>\n      <td>-0.124177</td>\n      <td>-1.186890</td>\n      <td>-0.303900</td>\n      <td>-2.035896e-01</td>\n      <td>1.103056e+00</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1564</th>\n      <td>-0.485220</td>\n      <td>-1.447220</td>\n      <td>0.195859</td>\n      <td>-0.650359</td>\n      <td>-0.060148</td>\n      <td>0.0</td>\n      <td>-0.273986</td>\n      <td>-0.114356</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-9.907605e-01</td>\n      <td>-0.410378</td>\n      <td>-0.001034</td>\n      <td>0.068167</td>\n      <td>-0.002468</td>\n      <td>-0.142380</td>\n      <td>-0.894681</td>\n      <td>-9.714133e-01</td>\n      <td>-5.983777e-01</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1565</th>\n      <td>-1.627246</td>\n      <td>0.450858</td>\n      <td>-0.800571</td>\n      <td>-0.483761</td>\n      <td>-0.046793</td>\n      <td>0.0</td>\n      <td>-0.372966</td>\n      <td>-0.058381</td>\n      <td>-0.008962</td>\n      <td>-0.421077</td>\n      <td>...</td>\n      <td>-8.085176e-02</td>\n      <td>0.089306</td>\n      <td>0.144578</td>\n      <td>-0.012520</td>\n      <td>0.139376</td>\n      <td>0.383924</td>\n      <td>0.911745</td>\n      <td>7.736405e-01</td>\n      <td>-6.581942e-02</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1566</th>\n      <td>-0.946577</td>\n      <td>-0.562207</td>\n      <td>-0.173737</td>\n      <td>3.452906</td>\n      <td>-0.046344</td>\n      <td>0.0</td>\n      <td>-2.579517</td>\n      <td>0.187905</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>7.256186e-01</td>\n      <td>-0.410378</td>\n      <td>0.162051</td>\n      <td>0.041271</td>\n      <td>0.156519</td>\n      <td>-0.790138</td>\n      <td>-0.031232</td>\n      <td>-2.733918e-01</td>\n      <td>4.061977e-01</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1567 rows × 479 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:54.159559441Z",
     "start_time": "2024-09-12T07:14:54.138961820Z"
    }
   },
   "id": "b353657905b332c3",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feature = df.drop('Pass/Fail', axis=1)\n",
    "target = df['Pass/Fail']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:54.160234568Z",
     "start_time": "2024-09-12T07:14:54.151094552Z"
    }
   },
   "id": "c8e3542113ddc73b",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0      -1\n1      -1\n2       1\n3      -1\n4      -1\n       ..\n1562   -1\n1563   -1\n1564   -1\n1565   -1\n1566   -1\nName: Pass/Fail, Length: 1567, dtype: int64"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:54.206058506Z",
     "start_time": "2024-09-12T07:14:54.156998783Z"
    }
   },
   "id": "5836320abc6dc3bc",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4    5         6  \\\n0     0.224309  0.849725 -0.436273  0.033555 -0.050580  0.0 -0.563790   \n1     1.107136 -0.382910  1.017137  0.153067 -0.060045  0.0  0.198217   \n2    -1.114158  0.799102 -0.481289  0.686213 -0.047906  0.0 -0.906210   \n3    -0.350312 -0.198875 -0.051547 -1.106948 -0.051290  0.0  0.503246   \n4     0.242143  0.087526  1.117387 -0.158919 -0.047492  0.0 -0.115382   \n...        ...       ...       ...       ...       ...  ...       ...   \n1562 -1.566122 -0.392636 -0.708645  3.842373 -0.048368  0.0 -3.039363   \n1563  0.515363  0.332906 -0.067433 -0.618139 -0.059208  0.0 -0.425952   \n1564 -0.485220 -1.447220  0.195859 -0.650359 -0.060148  0.0 -0.273986   \n1565 -1.627246  0.450858 -0.800571 -0.483761 -0.046793  0.0 -0.372966   \n1566 -0.946577 -0.562207 -0.173737  3.452906 -0.046344  0.0 -2.579517   \n\n             7         8         9  ...           580           581       582  \\\n0     0.266269  0.509826  1.128417  ...  4.436053e-16  2.587617e-16  0.118699   \n1     0.322244  0.456999  0.022582  ...  3.089342e-01  2.007880e+00  0.530203   \n2     0.255074 -0.260907  0.327183  ...  4.809624e+00 -2.744816e-01 -1.262780   \n3    -0.013602  0.343218 -0.765408  ... -5.093731e-01 -4.386698e-01 -0.322199   \n4     0.187905  0.545044 -0.149584  ...  4.436053e-16  2.587617e-16 -5.906899   \n...        ...       ...       ...  ...           ...           ...       ...   \n1562  0.333438 -1.631702 -0.242289  ... -3.559405e-01  1.916244e+00 -0.380985   \n1563 -0.147940 -0.400425 -0.348237  ...  4.436053e-16  2.587617e-16 -0.763096   \n1564 -0.114356  0.000000  0.000000  ... -1.481113e+00 -9.907605e-01 -0.410378   \n1565 -0.058381 -0.008962 -0.421077  ...  1.076097e+00 -8.085176e-02  0.089306   \n1566  0.187905  0.000000  0.000000  ... -4.582289e-01  7.256186e-01 -0.410378   \n\n            583        584        585       586       587           588  \\\n0     -0.204890  -0.093207  -0.197113  0.000000  0.000000 -3.027186e-16   \n1      0.406679   0.444706   0.385059 -0.960174  0.411853  2.501244e-01   \n2      0.022264   0.014375   0.029833  2.991151  3.627063  3.321419e+00   \n3     -0.292257  -0.362164  -0.283417 -0.101895 -0.178927 -3.082928e-01   \n4     26.867231  27.071425  26.913347 -0.101895 -0.178927 -3.082928e-01   \n...         ...        ...        ...       ...       ...           ...   \n1562  -0.059279   0.014375  -0.056191 -1.186890 -0.303900 -2.035896e-01   \n1563  -0.129172  -0.066312  -0.124177 -1.186890 -0.303900 -2.035896e-01   \n1564  -0.001034   0.068167  -0.002468 -0.142380 -0.894681 -9.714133e-01   \n1565   0.144578  -0.012520   0.139376  0.383924  0.911745  7.736405e-01   \n1566   0.162051   0.041271   0.156519 -0.790138 -0.031232 -2.733918e-01   \n\n               589  \n0     1.514500e-16  \n1     1.156689e+00  \n2    -1.791486e-01  \n3    -2.752459e-01  \n4    -2.752459e-01  \n...            ...  \n1562  1.103056e+00  \n1563  1.103056e+00  \n1564 -5.983777e-01  \n1565 -6.581942e-02  \n1566  4.061977e-01  \n\n[1567 rows x 478 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>580</th>\n      <th>581</th>\n      <th>582</th>\n      <th>583</th>\n      <th>584</th>\n      <th>585</th>\n      <th>586</th>\n      <th>587</th>\n      <th>588</th>\n      <th>589</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.224309</td>\n      <td>0.849725</td>\n      <td>-0.436273</td>\n      <td>0.033555</td>\n      <td>-0.050580</td>\n      <td>0.0</td>\n      <td>-0.563790</td>\n      <td>0.266269</td>\n      <td>0.509826</td>\n      <td>1.128417</td>\n      <td>...</td>\n      <td>4.436053e-16</td>\n      <td>2.587617e-16</td>\n      <td>0.118699</td>\n      <td>-0.204890</td>\n      <td>-0.093207</td>\n      <td>-0.197113</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-3.027186e-16</td>\n      <td>1.514500e-16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.107136</td>\n      <td>-0.382910</td>\n      <td>1.017137</td>\n      <td>0.153067</td>\n      <td>-0.060045</td>\n      <td>0.0</td>\n      <td>0.198217</td>\n      <td>0.322244</td>\n      <td>0.456999</td>\n      <td>0.022582</td>\n      <td>...</td>\n      <td>3.089342e-01</td>\n      <td>2.007880e+00</td>\n      <td>0.530203</td>\n      <td>0.406679</td>\n      <td>0.444706</td>\n      <td>0.385059</td>\n      <td>-0.960174</td>\n      <td>0.411853</td>\n      <td>2.501244e-01</td>\n      <td>1.156689e+00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.114158</td>\n      <td>0.799102</td>\n      <td>-0.481289</td>\n      <td>0.686213</td>\n      <td>-0.047906</td>\n      <td>0.0</td>\n      <td>-0.906210</td>\n      <td>0.255074</td>\n      <td>-0.260907</td>\n      <td>0.327183</td>\n      <td>...</td>\n      <td>4.809624e+00</td>\n      <td>-2.744816e-01</td>\n      <td>-1.262780</td>\n      <td>0.022264</td>\n      <td>0.014375</td>\n      <td>0.029833</td>\n      <td>2.991151</td>\n      <td>3.627063</td>\n      <td>3.321419e+00</td>\n      <td>-1.791486e-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.350312</td>\n      <td>-0.198875</td>\n      <td>-0.051547</td>\n      <td>-1.106948</td>\n      <td>-0.051290</td>\n      <td>0.0</td>\n      <td>0.503246</td>\n      <td>-0.013602</td>\n      <td>0.343218</td>\n      <td>-0.765408</td>\n      <td>...</td>\n      <td>-5.093731e-01</td>\n      <td>-4.386698e-01</td>\n      <td>-0.322199</td>\n      <td>-0.292257</td>\n      <td>-0.362164</td>\n      <td>-0.283417</td>\n      <td>-0.101895</td>\n      <td>-0.178927</td>\n      <td>-3.082928e-01</td>\n      <td>-2.752459e-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.242143</td>\n      <td>0.087526</td>\n      <td>1.117387</td>\n      <td>-0.158919</td>\n      <td>-0.047492</td>\n      <td>0.0</td>\n      <td>-0.115382</td>\n      <td>0.187905</td>\n      <td>0.545044</td>\n      <td>-0.149584</td>\n      <td>...</td>\n      <td>4.436053e-16</td>\n      <td>2.587617e-16</td>\n      <td>-5.906899</td>\n      <td>26.867231</td>\n      <td>27.071425</td>\n      <td>26.913347</td>\n      <td>-0.101895</td>\n      <td>-0.178927</td>\n      <td>-3.082928e-01</td>\n      <td>-2.752459e-01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1562</th>\n      <td>-1.566122</td>\n      <td>-0.392636</td>\n      <td>-0.708645</td>\n      <td>3.842373</td>\n      <td>-0.048368</td>\n      <td>0.0</td>\n      <td>-3.039363</td>\n      <td>0.333438</td>\n      <td>-1.631702</td>\n      <td>-0.242289</td>\n      <td>...</td>\n      <td>-3.559405e-01</td>\n      <td>1.916244e+00</td>\n      <td>-0.380985</td>\n      <td>-0.059279</td>\n      <td>0.014375</td>\n      <td>-0.056191</td>\n      <td>-1.186890</td>\n      <td>-0.303900</td>\n      <td>-2.035896e-01</td>\n      <td>1.103056e+00</td>\n    </tr>\n    <tr>\n      <th>1563</th>\n      <td>0.515363</td>\n      <td>0.332906</td>\n      <td>-0.067433</td>\n      <td>-0.618139</td>\n      <td>-0.059208</td>\n      <td>0.0</td>\n      <td>-0.425952</td>\n      <td>-0.147940</td>\n      <td>-0.400425</td>\n      <td>-0.348237</td>\n      <td>...</td>\n      <td>4.436053e-16</td>\n      <td>2.587617e-16</td>\n      <td>-0.763096</td>\n      <td>-0.129172</td>\n      <td>-0.066312</td>\n      <td>-0.124177</td>\n      <td>-1.186890</td>\n      <td>-0.303900</td>\n      <td>-2.035896e-01</td>\n      <td>1.103056e+00</td>\n    </tr>\n    <tr>\n      <th>1564</th>\n      <td>-0.485220</td>\n      <td>-1.447220</td>\n      <td>0.195859</td>\n      <td>-0.650359</td>\n      <td>-0.060148</td>\n      <td>0.0</td>\n      <td>-0.273986</td>\n      <td>-0.114356</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-1.481113e+00</td>\n      <td>-9.907605e-01</td>\n      <td>-0.410378</td>\n      <td>-0.001034</td>\n      <td>0.068167</td>\n      <td>-0.002468</td>\n      <td>-0.142380</td>\n      <td>-0.894681</td>\n      <td>-9.714133e-01</td>\n      <td>-5.983777e-01</td>\n    </tr>\n    <tr>\n      <th>1565</th>\n      <td>-1.627246</td>\n      <td>0.450858</td>\n      <td>-0.800571</td>\n      <td>-0.483761</td>\n      <td>-0.046793</td>\n      <td>0.0</td>\n      <td>-0.372966</td>\n      <td>-0.058381</td>\n      <td>-0.008962</td>\n      <td>-0.421077</td>\n      <td>...</td>\n      <td>1.076097e+00</td>\n      <td>-8.085176e-02</td>\n      <td>0.089306</td>\n      <td>0.144578</td>\n      <td>-0.012520</td>\n      <td>0.139376</td>\n      <td>0.383924</td>\n      <td>0.911745</td>\n      <td>7.736405e-01</td>\n      <td>-6.581942e-02</td>\n    </tr>\n    <tr>\n      <th>1566</th>\n      <td>-0.946577</td>\n      <td>-0.562207</td>\n      <td>-0.173737</td>\n      <td>3.452906</td>\n      <td>-0.046344</td>\n      <td>0.0</td>\n      <td>-2.579517</td>\n      <td>0.187905</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-4.582289e-01</td>\n      <td>7.256186e-01</td>\n      <td>-0.410378</td>\n      <td>0.162051</td>\n      <td>0.041271</td>\n      <td>0.156519</td>\n      <td>-0.790138</td>\n      <td>-0.031232</td>\n      <td>-2.733918e-01</td>\n      <td>4.061977e-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>1567 rows × 478 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:54.206935558Z",
     "start_time": "2024-09-12T07:14:54.197709234Z"
    }
   },
   "id": "872269d084564de1",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, \\\n",
    "                                                    test_size=0.2, random_state=11, stratify=target)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'max_depth': [5, 7],\n",
    "    'subsample': [0.8,1.0],\n",
    "    'colsample_bytree': [0.7,1.0],\n",
    "    'gamma': [0,0.2],\n",
    "}\n",
    "\n",
    "y_train = [0 if label == -1 else 1 for label in y_train]\n",
    "y_test = [0 if label == -1 else 1 for label in y_test]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:54.207264707Z",
     "start_time": "2024-09-12T07:14:54.197913762Z"
    }
   },
   "id": "c7a33d051311f310",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:14:54.207554375Z",
     "start_time": "2024-09-12T07:14:54.197965553Z"
    }
   },
   "id": "a3ba4d4d5fe2c80a",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 64 candidates, totalling 128 fits\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=400, subsample=0.8; total time=   3.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m model \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mXGBClassifier(eval_metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauc\u001B[39m\u001B[38;5;124m'\u001B[39m, tree_method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhist\u001B[39m\u001B[38;5;124m'\u001B[39m, scale_pos_weight\u001B[38;5;241m=\u001B[39mclass_weights[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     13\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(model, param_grid, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbalanced_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest parameters: \u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[1;32m     16\u001B[0m best_model \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator_\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/sklearn/base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1349\u001B[0m     )\n\u001B[1;32m   1350\u001B[0m ):\n\u001B[0;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    966\u001B[0m     )\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/sklearn/model_selection/_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    913\u001B[0m         )\n\u001B[1;32m    914\u001B[0m     )\n\u001B[0;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    939\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/sklearn/utils/parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/sklearn/utils/parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:890\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    888\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    889\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 890\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    893\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    894\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/xgboost/core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/xgboost/sklearn.py:1531\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[0m\n\u001B[1;32m   1511\u001B[0m model, metric, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(xgb_model, params)\n\u001B[1;32m   1512\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[1;32m   1513\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[1;32m   1514\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1528\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[1;32m   1529\u001B[0m )\n\u001B[0;32m-> 1531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1534\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1535\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1536\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1537\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1538\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1539\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1540\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[1;32m   1546\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/xgboost/core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/xgboost/training.py:181\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 181\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miteration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/forpytorch/lib/python3.9/site-packages/xgboost/core.py:2101\u001B[0m, in \u001B[0;36mBooster.update\u001B[0;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[1;32m   2097\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_dmatrix_features(dtrain)\n\u001B[1;32m   2099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2100\u001B[0m     _check_call(\n\u001B[0;32m-> 2101\u001B[0m         \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2102\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\n\u001B[1;32m   2103\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2104\u001B[0m     )\n\u001B[1;32m   2105\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2106\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "학습시간이 오래 걸리니 해당 셀은 신중하게 실행하십시오.\n",
    "'''\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "if os.path.exists('/best_xgboost_model.pkl'):\n",
    "    best_model = joblib.load('best_xgboost_model.pkl')\n",
    "else:\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    model = xgb.XGBClassifier(eval_metric='auc', tree_method='hist', scale_pos_weight=class_weights[1])\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=2, scoring='balanced_accuracy', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    best_model = grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T07:15:03.415913183Z",
     "start_time": "2024-09-12T07:14:54.197992662Z"
    }
   },
   "id": "aabb632175e82d9c",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "f1 = f1_score(best_model.predict(X_test), y_test)\n",
    "balance = balanced_accuracy_score(best_model.predict(X_test), y_test)\n",
    "print(f'f1 score is : {f1}')\n",
    "print(f'balanced score is : {balance}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T07:15:03.410644484Z"
    }
   },
   "id": "d64ad5e21b65fa79",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_model, 'best_xgboost_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T07:15:03.411731426Z"
    }
   },
   "id": "5ea2fb6786c9fb1e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "best_model = joblib.load('best_xgboost_model.pkl')\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "balance = balanced_accuracy_score(y_pred, y_test)\n",
    "print(f'f1 score is : {f1}')\n",
    "print(f'balanced score is : {balance}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T07:15:03.412809978Z"
    }
   },
   "id": "3fe08567ae372752",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T07:15:03.413469411Z"
    }
   },
   "id": "d3d12538d28076eb",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
